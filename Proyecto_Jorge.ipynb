{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Proyecto de Introducción a Data Science\n",
    "# Uso de Procesamiento de Lenguaje Natural para la Clasificación de Informes de Práctica Pre Profesional\n",
    "\n",
    "#### Equipo H-ROCHIS:\n",
    "- David Araya, 20.767.691-8\n",
    "- Jorge Rivera, 20.416.699-4\n",
    "- José Alcayaga,  20.967.432-7\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# Resumen Ejecutivo\n",
    "\n",
    "Durante el proceso de revisión de los informes de práctica del DISC (Departamento de Ingeniería de Sistemas y Computación), se requiere una inversión considerable de tiempo que, hasta la fecha, no ha sido automatizada. Esto conlleva largas jornadas de trabajo y carga adicional para los académicos, quienes podrían emplear ese tiempo en otras labores. Por lo tanto, como equipo de trabajo, hemos llegado a un consenso en la necesidad de llevar a cabo el análisis y desarrollo de un modelo que permita clasificar los informes en las categorías definidas en la rúbrica actual (insatisfactorio, regular, bueno y excelente).\n",
    "Es importante destacar que, con la llegada de la pandemia, la entrega de informes ha sido en formato digital, lo que ha generado un conjunto de aproximadamente 100 informes disponibles. Esta digitalización ofrece ventajas significativas para el entrenamiento del modelo, ya que se dispone de datos de entrada y resultados concretos (informe, rúbrica y nota).\n",
    "\n",
    "## Objetivo General\n",
    "\n",
    "Desarrollar un sistema basado en técnicas de aprendizaje automático que permita la clasificación automatizada de informes de práctica del DISC en las categorías definidas en la rúbrica actual (insatisfactorio, regular, bueno y excelente), utilizando como base un conjunto de datos digitalizados de aproximadamente 100 informes.\n",
    "\n",
    "## Objetivos Específicos\n",
    "1. Preprocesar un conjunto de informes digitalizados para ser utilizados como datos de entrenamiento y prueba.\n",
    "2. Entrenar uno o varios modelos de aprendizaje automático utilizando técnicas de procesamiento de lenguaje natural (NLP).\n",
    "3. Evaluar las diferencias entre el conjunto inicial y las clasificaciones del modelo.\n",
    "\n",
    "## Progresos por cada Objetivo Especifico\n",
    "1. Se optimiza de manera preliminar el contenido de los informes para ser procesados por modelos modernos de representación, como BERT. En particular, se divide un informe en un conjunto de bloques de información, los cuales son obtenidos directamente de la librería PyMuPDF.\n",
    "2. En lo que respecta a métodos tradicionales, se prueban modelos de salidas múltiples, para obtener las predicciones de los distintos elementos de la rúbrica. De manera experimental, se definen tambien modelos para predecir la calificación final en base a los elementos de la rúbrica. Además, se agrega al conjunto de modelos: un clasificador Naïve Bayes, un bosque aleatorio, y un árbol de decisión mejorado por gradiente, por parte de la librería XGBoost.\n",
    "Para aumentar el rendimiento de los modelos, se aplicó búsqueda de hiperparámetros por grilla.\n",
    "Pasando a métodos de deep learning, se implementa un modelo basado en LSTM, que predice cada elemento de la rúbrica de manera independiente. En particular, se generan 2 modelos bases, para los distintos métodos de representación que se probaron. De estos, se generaron siete instancias, para los seis elementos de la rúbrica y la calificación final.\n",
    "3. Se evaluó el rendimiento de los modelos basados en Deep Learning. En general, ninguno de los modelos obtuvo una exactitud mayor a 60%, teniendo la mayoría uno menor a 50%. Por el lado de los modelos tradicionales, los nuevos modelos integrados tienen una  puntuación similar o peor a los modelos previamente mostrados: 56% para Naïve Bayes, 54% para bosque aleatorio, y 43% para XGBoost; y los modelos de multiple salida presentan valores de presición menores a 10%.\n",
    "\n",
    "> **Nota:** Las dos celdas siguientes contienen los comandos necesarios para instalar las bibliotecas utilizadas a lo largo del cuaderno. Puedes ejecutarlas directamente como celdas de código o copiar y pegar cada comando en una terminal, excluyendo el signo de exclamación."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!python -m pip install pymupdf pandas openpyxl tensorflow tensorflow_hub tensorflow-text spacy classy-classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!python -m spacy download es_dep_news_trf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Librerías generales\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Procesamiento de texto\n",
    "import spacy\n",
    "from spacy_transformers import Transformer\n",
    "from spacy_transformers.pipeline_component import DEFAULT_CONFIG\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "from transformers import pipeline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from classy_classification import ClassyClassifier\n",
    "import torch\n",
    "\n",
    "# PDF handling\n",
    "import fitz\n",
    "\n",
    "# Red neuronal con Keras\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "from keras.models import Sequential, clone_model\n",
    "from keras import utils\n",
    "\n",
    "# Operaciones numéricas\n",
    "from numpy import floor\n",
    "\n",
    "# Tabulate para imprimir tablas\n",
    "from tabulate import tabulate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:22:58.688964800Z",
     "start_time": "2023-12-15T02:22:58.644315800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definición de Funciones a Utilizar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_classification(grade, number=False):\n",
    "    grade = round(grade, 1)\n",
    "    if grade < 4:\n",
    "        return \"insatisfactorio\" if not number else 0\n",
    "    elif 4 <= grade < 5.5:\n",
    "        return \"regular\" if not number else 1\n",
    "    elif 5.5 <= grade < 6.5:\n",
    "        return \"bueno\" if not number else 2\n",
    "    elif 6.5 <= grade <= 7:\n",
    "        return \"excelente\" if not number else 3\n",
    "\n",
    "def get_final_grade(rubric_grades):\n",
    "    result = rubric_grades[\"estructura\"] * 0.5\n",
    "    result += rubric_grades[\"escritura\"] * 0.15\n",
    "    result += rubric_grades[\"contenido\"] * 0.25\n",
    "    result += rubric_grades[\"conclusiones\"] * 0.15\n",
    "    result += rubric_grades[\"conocimiento\"] * 0.30\n",
    "    result += rubric_grades[\"relevancia\"] * 0.10\n",
    "    return floor(result)\n",
    "\n",
    "def print_formatted_table(column_names, *columns):\n",
    "    columns = [[value.capitalize() if isinstance(value, str) else value for value in col] for col in columns]\n",
    "    data = list(zip(*columns))\n",
    "    print(tabulate(data, headers=column_names, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "def print_parameters(parameters):\n",
    "    table_data = [(key, value) for key, value in parameters.items()]\n",
    "    print(tabulate(table_data, headers=[\"Parámetro\", \"Valor\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    table_data = [(metric_name, metric_value) for metric_name, metric_value in metrics.items()]\n",
    "    print(tabulate(table_data, headers=[\"Métrica\", \"Valor\"], tablefmt=\"fancy_grid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:02.881767100Z",
     "start_time": "2023-12-15T02:23:02.829921200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Recolección de Datos\n",
    "\n",
    "En esta sección, se carga la información del archivo \"calificaciones.xlsx\" en el dataframe dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "dataset = pd.read_excel(\"calificaciones.xlsx\", decimal=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:05.936359400Z",
     "start_time": "2023-12-15T02:23:05.816495200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Procesamiento de Datos\n",
    "\n",
    "En esta sección, se identifican y seleccionan las columnas relevantes para las calificaciones y la rúbrica, excluyendo aquellas innecesarias. Luego, se procede a eliminar las filas que contienen valores nulos en las columnas de calificaciones. Posteriormente, se inicia el procesamiento de documentos en formato PDF con el propósito de extraer información relevante e incorporarla al conjunto de datos.\n",
    "\n",
    "Se implementa la clasificación de documentos basada en las calificaciones obtenidas en cada entrada, siguiendo las categorías predefinidas en la rúbrica. Cada nota asociada a los componentes de cada informe se sustituye por un elemento que representa la categoría correspondiente. Este elemento puede ser un texto que refleje directamente el nombre de la categoría o un número, variando desde 0 para \"insuficiente\" hasta 3 para \"excelente\".\n",
    "\n",
    "La elección entre texto y número tiene un propósito específico: el texto se utiliza exclusivamente para el modelo Classy Classification, mientras que los números se emplean para los demás modelos. Esta adaptación facilita la integración de los datos clasificados en los diferentes modelos, asegurando la coherencia necesaria para cada enfoque de análisis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "grades_columns = dataset.columns.difference([\"id\", \"periodo\", \"Unnamed: 9\"])\n",
    "rubric_columns = grades_columns.difference([\"total\"])\n",
    "dataset = dataset.dropna(subset=grades_columns)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for id in dataset[\"id\"]:\n",
    "    pdf_file = fitz.open(f\"dataset/{id}.pdf\")\n",
    "    document_text = chr(12).join([page.get_text() for page in pdf_file])\n",
    "    documents.append(document_text)\n",
    "\n",
    "dataset.insert(loc=2, column=\"documents\", value=documents)\n",
    "\n",
    "text_labeled_dataset = dataset.copy()\n",
    "text_labeled_dataset.loc[:, grades_columns] = text_labeled_dataset.loc[:, grades_columns].apply(lambda s: s.apply(get_classification))\n",
    "\n",
    "dataset.loc[:, grades_columns] = dataset.loc[:, grades_columns].apply(lambda s: s.apply(lambda x: get_classification(grade=x, number=True)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:19.373838900Z",
     "start_time": "2023-12-15T02:23:07.395000400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Exploración y Visualización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Análisis y Machine Learning\n",
    "\n",
    "## Clasificación de documentos con métodos tradicionales\n",
    "\n",
    "SciKit-Learn será la herramienta empleada para analizar documentos a través de métodos tradicionales de NLP, centrándose especialmente en TF-IDF. En esta fase, se implementa la división en conjuntos de prueba y validación, además de aplicar la vectorización.\n",
    "\n",
    "Posteriormente, se recurrirá a diversos modelos de Machine Learning para llevar a cabo la clasificación de los documentos. Entre estos modelos se incluyen la regresión lineal y logística, SVM, árboles de decisión y Naïve Bayes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "Xn = dataset[\"documents\"]\n",
    "yn = dataset[grades_columns]\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, yn, random_state=3, test_size=0.3)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.9, min_df=0.2)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:24.773167300Z",
     "start_time": "2023-12-15T02:23:19.384401600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimadores de calificación final\n",
    "\n",
    "A modo de experimentación, para obtener un modelo que pueda predecir una calificación final considerando una predicción de todos los elementos, se intentan hacer modelos que puedan definir la categoría final en base a los elementos de la rúbrica. Además, se prueba aplicando la fórmula de nota final considerando solamente las categorías de la rúbrica."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════╕\n",
      "│ Métrica   │   Valor │\n",
      "╞═══════════╪═════════╡\n",
      "│ Accuracy  │ 0.33908 │\n",
      "╘═══════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "y_calc = get_final_grade(yn[rubric_columns])\n",
    "acc = accuracy_score(y_calc, yn[\"total\"])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:24.838917100Z",
     "start_time": "2023-12-15T02:23:24.791705300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calificación final con Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"random_state\": [1, 5, 10, 12, 27, 42, 64, 130],\n",
    "    \"n_estimators\": [100, 150, 175, 200],\n",
    "    \"max_depth\": [1, 3, 5, 6, 7, 10],\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "grid = GridSearchCV(rf, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_grade_rf = RandomForestClassifier(n_estimators=100, random_state=12, max_depth=5)\n",
    "final_grade_rf.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "grade_pred_rf = final_grade_rf.predict(y_test[rubric_columns])\n",
    "\n",
    "acc = accuracy_score(y_test[\"total\"], grade_pred_rf)\n",
    "f1 = f1_score(y_test[\"total\"], grade_pred_rf, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_formatted_table([\"Rúbrica\", \"Importancia\"], rubric_columns, final_grade_rf.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calificación final con SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "final_grade_svc_n = SVC()\n",
    "grid = GridSearchCV(final_grade_svc_n, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_grade_svc_n = SVC(C=10)\n",
    "final_grade_svc_n.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "grade_pred = final_grade_svc_n.predict(y_test[rubric_columns])\n",
    "\n",
    "acc = accuracy_score(y_test[\"total\"], grade_pred)\n",
    "f1 = f1_score(y_test[\"total\"], grade_pred, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calificación final con Regresión Logística"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════╤═════════╕\n",
      "│ Parámetro   │   Valor │\n",
      "╞═════════════╪═════════╡\n",
      "│ C           │       5 │\n",
      "╘═════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "final_grade_log = LogisticRegression(max_iter=1000)\n",
    "grid = GridSearchCV(final_grade_log, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:25.901484600Z",
     "start_time": "2023-12-15T02:23:24.824383300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤══════════╕\n",
      "│ Métrica   │    Valor │\n",
      "╞═══════════╪══════════╡\n",
      "│ Accuracy  │ 0.867925 │\n",
      "├───────────┼──────────┤\n",
      "│ F1        │ 0.868735 │\n",
      "╘═══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "final_grade_log = LogisticRegression(max_iter=1000, C=5)\n",
    "final_grade_log.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "grade_pred_log = final_grade_log.predict(y_test[rubric_columns])\n",
    "\n",
    "acc = accuracy_score(y_test[\"total\"], grade_pred_log)\n",
    "f1 = f1_score(y_test[\"total\"], grade_pred_log, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:23:25.953774600Z",
     "start_time": "2023-12-15T02:23:25.894474Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calificación final con Naïve Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "final_grade_nb = CategoricalNB()\n",
    "grid = GridSearchCV(final_grade_nb, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_grade_nb = CategoricalNB()\n",
    "final_grade_nb.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "grade_pred_nb = final_grade_nb.predict(y_test[rubric_columns])\n",
    "\n",
    "acc = accuracy_score(y_test[\"total\"], grade_pred_nb)\n",
    "f1 = f1_score(y_test[\"total\"], grade_pred_nb, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calificación final con XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [150, 175, 200],\n",
    "    \"learning_rate\": [0.1, 0.2, 0.3],\n",
    "    \"reg_lambda\": [0.5, 1, 2],\n",
    "    \"reg_alpha\": [0.25, 0.5, 0.75],\n",
    "}\n",
    "final_grade_xgb = XGBClassifier()\n",
    "grid = GridSearchCV(final_grade_xgb, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(yn[rubric_columns], yn[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_grade_xgb = XGBClassifier(n_estimators=150, learning_rate=0.1, reg_alpha=0.25)\n",
    "final_grade_xgb.fit(y_train[rubric_columns], y_train[\"total\"])\n",
    "grade_pred_xgb = final_grade_xgb.predict(y_test[rubric_columns])\n",
    "\n",
    "acc = accuracy_score(y_test[\"total\"], grade_pred_xgb)\n",
    "f1 = f1_score(y_test[\"total\"], grade_pred_xgb, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimadores de calificación por documento\n",
    "\n",
    "#### Clasificación de documentos con SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "svc_n = SVC()\n",
    "grid = GridSearchCV(svc_n, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_n = SVC(C=5)\n",
    "svc_n.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred = svc_n.predict(X_test_bow)\n",
    "acc = accuracy_score(y_test[\"total\"], y_pred)\n",
    "f1 = f1_score(y_test[\"total\"], y_pred, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc, \"F1\": f1}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_n_mo = MultiOutputClassifier(svc_n)\n",
    "svc_n_mo.fit(X_train_bow, y_train[rubric_columns])\n",
    "y_pred_mo = svc_n_mo.predict(X_test_bow)\n",
    "\n",
    "acc_mo = svc_n_mo.score(X_test_bow, y_test[rubric_columns])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_mo}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Regresión Ridge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "ridge = RidgeClassifier(max_iter=1000)\n",
    "grid = GridSearchCV(ridge, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier()\n",
    "ridge.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred_r = ridge.predict(X_test_bow)\n",
    "\n",
    "acc_r = accuracy_score(y_test[\"total\"], y_pred_r)\n",
    "f1_r = f1_score(y_test[\"total\"], y_pred_r, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_r, \"F1\": f1_r}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge_mo = MultiOutputClassifier(ridge)\n",
    "ridge_mo.fit(X_train_bow, y_train[rubric_columns])\n",
    "y_pred_r_mo = ridge_mo.predict(X_test_bow)\n",
    "\n",
    "acc_r_mo = ridge_mo.score(X_test_bow, y_test[rubric_columns])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_r_mo}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Regresión Logística"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "grid = GridSearchCV(log, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred_l = log.predict(X_test_bow)\n",
    "\n",
    "acc_l = accuracy_score(y_test[\"total\"], y_pred_l)\n",
    "f1_l = f1_score(y_test[\"total\"], y_pred_l, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_r, \"F1\": f1_r}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_mo = MultiOutputClassifier(log)\n",
    "log_mo.fit(X_train_bow, y_train[rubric_columns])\n",
    "y_pred_log_mo = log_mo.predict(X_test_bow)\n",
    "\n",
    "acc_log_mo = log_mo.score(X_test_bow, y_test[rubric_columns])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_log_mo}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"random_state\": [1, 5, 10, 12, 27, 42, 64, 130],\n",
    "    \"n_estimators\": [100, 150, 175, 200],\n",
    "    \"max_depth\": [1, 3, 5, 6, 7, 10],\n",
    "}\n",
    "rf = RandomForestClassifier()\n",
    "grid = GridSearchCV(rf, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=12)\n",
    "rf.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred_rf = rf.predict(X_test_bow)\n",
    "\n",
    "acc_rf = accuracy_score(y_test[\"total\"], y_pred_rf)\n",
    "f1_rf = f1_score(y_test[\"total\"], y_pred_rf, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_rf, \"F1\": f1_rf}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_mo = MultiOutputClassifier(rf)\n",
    "rf_mo.fit(X_train_bow, y_train[rubric_columns])\n",
    "y_pred_rf_mo = rf_mo.predict(X_test_bow)\n",
    "\n",
    "acc_rf_mo = rf_mo.score(X_test_bow, y_test[rubric_columns])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_rf_mo}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Naïve Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n",
    "}\n",
    "nb = MultinomialNB()\n",
    "grid = GridSearchCV(nb, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred_nb = nb.predict(X_test_bow)\n",
    "\n",
    "acc_nb = accuracy_score(y_test[\"total\"], y_pred_nb)\n",
    "f1_nb = f1_score(y_test[\"total\"], y_pred_nb, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_nb, \"F1\": f1_nb}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"random_state\": [1, 5, 10, 12, 27, 42, 64, 130],\n",
    "    \"n_estimators\": [150, 175, 200],\n",
    "    \"learning_rate\": [0.1, 0.2, 0.3],\n",
    "    \"reg_lambda\": [0.5, 1, 2],\n",
    "    \"reg_alpha\": [0.25, 0.5, 0.75],\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "grid = GridSearchCV(xgb, param_grid, scoring=(\"accuracy\", \"f1_weighted\"), refit=\"accuracy\", cv=3)\n",
    "grid.fit(X_train_bow, y_train[\"total\"])\n",
    "\n",
    "print_parameters(grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_bow, y_train[\"total\"])\n",
    "y_pred_xgb = xgb.predict(X_test_bow)\n",
    "\n",
    "acc_xgb = accuracy_score(y_test[\"total\"], y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test[\"total\"], y_pred_xgb, average=\"weighted\")\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_xgb, \"F1\": f1_xgb}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_mo = MultiOutputClassifier(xgb)\n",
    "xgb_mo.fit(X_train_bow, y_train[rubric_columns])\n",
    "y_pred_xgb_mo = xgb_mo.predict(X_test_bow)\n",
    "\n",
    "acc_xgb_mo = xgb_mo.score(X_test_bow, y_test[rubric_columns])\n",
    "\n",
    "metrics_dict = {\"Accuracy\": acc_xgb_mo}\n",
    "print_metrics(metrics_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Vuelta al Procesamiento de Datos\n",
    "\n",
    "El **número de párafos** (PARAGRAPH_QTY) corresponde al mayor número de bloques encontrado en un documento, aproximado a la siguiente mayor potencia de dos.\n",
    "\n",
    "El **tamaño de lote** (BATCH_SIZE) corresponde a la cantidad de documentos que se procesaran. Además, para facilitar el trabajo de clasificación por parte del modelo, se transforman las categorías a una lista de representación binaria."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "documents = []\n",
    "for id in dataset[\"id\"]:\n",
    "    pdf_file = fitz.open(f\"dataset/{id}.pdf\")\n",
    "    document_text = [] \n",
    "    for page in pdf_file:\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        document_text += [block[4] for block in blocks]\n",
    "    documents.append(document_text)\n",
    "dataset.insert(loc=2, column=\"block_documents\", value=documents)\n",
    "\n",
    "PARAGRAPH_QTY = 2048\n",
    "BATCH_SIZE= 171\n",
    "\n",
    "labels_total = utils.to_categorical(dataset[\"total\"], num_classes=4)\n",
    "labels_estructura = utils.to_categorical(dataset[\"estructura\"], num_classes=4)\n",
    "labels_escritura = utils.to_categorical(dataset[\"escritura\"], num_classes=4)\n",
    "labels_contenido = utils.to_categorical(dataset[\"contenido\"], num_classes=4)\n",
    "labels_conclusiones = utils.to_categorical(dataset[\"conclusiones\"], num_classes=4)\n",
    "labels_conocimiento = utils.to_categorical(dataset[\"conocimiento\"], num_classes=4)\n",
    "labels_relevancia = utils.to_categorical(dataset[\"relevancia\"], num_classes=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:41:49.734001Z",
     "start_time": "2023-12-15T02:41:15.058544900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Análisis y Machine Learning\n",
    "\n",
    "## Clasificación de documentos con Deep Learning\n",
    "\n",
    "### Clasificación de documentos con TensorFlow\n",
    "\n",
    "Se prueba un modelo LSTM para hacer la clasificación en base a una representación vectorial del cuerpo del documento.\n",
    "\n",
    "Por limitaciones técnicas y para evitar pérdida de información, cada documento se divide en un conjunto de bloques; por el momento se considera solamente la división propia del formato PDF.\n",
    "\n",
    "Así, la entrada del modelo LSTM sería un conjunto de lotes o muestras, que contemplan un conjunto de bloques, que a su vez son un vector de cierta dimensionalidad (determinada por el modelo de representación utilizado).\n",
    "\n",
    "Dado que el modelo LSTM requiere de entradas de tamaño fijo, se asignó un tamaño de entrada tal que todos los documentos pudieran ser transformados y aceptados por el modelo; para suplir el espacio restante de cada documento, se rellena la entrada con una representación de una cadena vacía.\n",
    "\n",
    "La búsqueda de modelos de representación se hizo priorizando el largo de entrada, y la posibilidad de trabajar con textos en español. Para acotar el trabajo a realizar, se escogieron 3 modelos a probar:\n",
    "- Universal Sentence Encoder - Multilingual Large: Tiene soporte para español y admite una entrada de tamaño arbitrario (a coste de posible pérdida de información).\n",
    "- Longformer Spanish: Modelo basado en BERT, mejorado para soportar entradas de hasta 4096 tokens, y entrenado específicamente en español.\n",
    "- Tulio BERT: Modelo basado en BERT, entrenado con un conjunto de datos chileno.\n",
    "\n",
    "Dentro del marco del proyecto, se exploraron opciones para optimizar el procesamiento de texto. En esta ocasión, se hizo la solicitud a la Unidad de HPC de la Facultad de Ingenierías y Ciencias Geológicas para aprovechar su clúster de alto rendimiento. A continuación, se tendrán distintas celdas en texto plano que contienen el código que se ejecutó en el clúster."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Universal Sentence Encoder - Multilingual Large"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "use_embedder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "use_pad = use_embedder(\"\")\n",
    "Xn_text_embed = [use_embedder(document) for document in dataset[\"block_documents\"]]\n",
    "padded_documents = []\n",
    "for document in Xn_text_embed:\n",
    "    pad = np.concatenate(np.repeat([use_pad], PARAGRAPH_QTY-document.shape[0], axis=0), axis=0)\n",
    "    padded_documents.append(tf.concat([document, pad], 0))\n",
    "Xn_tensor = tf.convert_to_tensor(padded_documents)\n",
    "serialized_Xn_use = tf.io.serialize_tensor(Xn_tensor)\n",
    "with open(\"use_padded.tensor\", \"wb\") as file:\n",
    "    file.write(serialized_Xn_use.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with open(\"use_padded.tensor\", \"rb\") as file:\n",
    "    serialized_Xn_tensor = file.read()\n",
    "opened_Xn_tensor = tf.io.parse_tensor(serialized_Xn_tensor, out_type=float)   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:08:48.797804Z",
     "start_time": "2023-12-15T02:08:41.736740100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_use = Sequential()\n",
    "model_use.add(Bidirectional(LSTM(512, return_sequences=False, input_shape=(PARAGRAPH_QTY, 512))))\n",
    "model_use.add(Dense(256, activation=\"relu\"))\n",
    "model_use.add(Dense(4, activation=\"softmax\"))\n",
    "model_use.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T02:08:49.136149500Z",
     "start_time": "2023-12-15T02:08:48.806811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 218s 218s/step - loss: 1.3771 - accuracy: 0.4628 - auc: 0.6833 - val_loss: 1.1871 - val_accuracy: 0.4906 - val_auc: 0.7472\n",
      "Epoch 2/3\n"
     ]
    }
   ],
   "source": [
    "model_use_total = clone_model(model_use)\n",
    "model_use_total.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_total.fit(opened_Xn_tensor, labels_total, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_total.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-15T02:08:49.125150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_contenido = clone_model(model_use)\n",
    "model_use_contenido.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_contenido.fit(opened_Xn_tensor, labels_contenido, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_contenido.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_conclusiones = clone_model(model_use)\n",
    "model_use_conclusiones.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_conclusiones.fit(opened_Xn_tensor, labels_conclusiones, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_conclusiones.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_conocimiento = clone_model(model_use)\n",
    "model_use_conocimiento.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_conocimiento.fit(opened_Xn_tensor, labels_conocimiento, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_conocimiento.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_relevancia = clone_model(model_use)\n",
    "model_use_relevancia.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_relevancia.fit(opened_Xn_tensor, labels_relevancia, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_relevancia.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_estructura = clone_model(model_use)\n",
    "model_use_estructura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_estructura.fit(opened_Xn_tensor, labels_estructura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_estructura.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_use_escritura = clone_model(model_use)\n",
    "model_use_escritura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_use_escritura.fit(opened_Xn_tensor, labels_escritura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_use_escritura.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Longformer - Spanish"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "long_tokenizer = RobertaTokenizer.from_pretrained(\"mrm8488/longformer-base-4096-spanish\",)\n",
    "long_model = RobertaModel.from_pretrained(\"mrm8488/longformer-base-4096-spanish\")\n",
    "inputs = long_tokenizer(\"\", return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = long_model(**inputs)\n",
    "cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "long_pad = tf.convert_to_tensor(cls_embeddings)\n",
    "inputs = long_tokenizer(\"\", return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = long_model(**inputs)\n",
    "cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "long_pad = tf.convert_to_tensor(cls_embeddings)\n",
    "def long_embedder(document):\n",
    "    embeddings = []\n",
    "    for page in document:\n",
    "        inputs = long_tokenizer(page, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = long_model(**inputs)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings)\n",
    "    print(\"done document\")\n",
    "    return tf.convert_to_tensor(torch.cat(embeddings))\n",
    "Xn_long_embed = [long_embedder(document) for document in dataset[\"block_documents\"]]\n",
    "padded_long_documents = []\n",
    "for document in Xn_long_embed:\n",
    "    pad = np.concatenate(np.repeat([long_pad], PARAGRAPH_QTY-document.shape[0], axis=0), axis=0)\n",
    "    padded_long_documents.append(tf.concat([document, pad], 0))\n",
    "Xn_long_tensor = tf.convert_to_tensor(padded_long_documents)\n",
    "serialized_Xn_long = tf.io.serialize_tensor(Xn_long_tensor)\n",
    "with open(\"long_padded.tensor\", \"wb\") as file:\n",
    "    file.write(serialized_Xn_long.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"long_padded.tensor\", \"rb\") as file:\n",
    "    serialized_Xn_long_tensor = file.read()\n",
    "opened_Xn_long_tensor = tf.io.parse_tensor(serialized_Xn_long_tensor, out_type=float)    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long = Sequential()\n",
    "model_long.add(Bidirectional(LSTM(512, return_sequences=False, input_shape=(PARAGRAPH_QTY, 768))))\n",
    "model_long.add(Dense(256, activation=\"relu\"))\n",
    "model_long.add(Dense(4, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_total = clone_model(model_long)\n",
    "model_long_total.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_total.fit(opened_Xn_long_tensor, labels_total, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_total.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_contenido = clone_model(model_long)\n",
    "model_long_contenido.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_contenido.fit(opened_Xn_long_tensor, labels_contenido, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_contenido.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_conclusiones = clone_model(model_long)\n",
    "model_long_conclusiones.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_conclusiones.fit(opened_Xn_long_tensor, labels_conclusiones, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_conclusiones.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_conocimiento = clone_model(model_long)\n",
    "model_long_conocimiento.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_conocimiento.fit(opened_Xn_long_tensor, labels_conocimiento, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_conocimiento.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_relevancia = clone_model(model_long)\n",
    "model_long_relevancia.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_relevancia.fit(opened_Xn_long_tensor, labels_relevancia, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_relevancia.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_estructura = clone_model(model_long)\n",
    "model_long_estructura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_estructura.fit(opened_Xn_long_tensor, labels_estructura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_estructura.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_long_escritura = clone_model(model_long)\n",
    "model_long_escritura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_long_escritura.fit(opened_Xn_long_tensor, labels_escritura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_long_escritura.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación de documentos con Tulio BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "tulio_tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/tulio-chilean-spanish-bert\")\n",
    "tulio_model = AutoModel.from_pretrained(\"dccuchile/tulio-chilean-spanish-bert\")\n",
    "tulio_pipe = pipeline(\"fill-mask\", model=\"dccuchile/tulio-chilean-spanish-bert\")\n",
    "inputs = tulio_tokenizer(\"\", return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = tulio_model(**inputs)\n",
    "cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "tulio_pad = tf.convert_to_tensor(cls_embeddings)\n",
    "def tulio_embedder(document):\n",
    "    embeddings = []\n",
    "    for page in document:\n",
    "        inputs = tulio_tokenizer(page, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = tulio_model(**inputs)\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings)\n",
    "    print(\"done document\")\n",
    "    return tf.convert_to_tensor(torch.cat(embeddings))\n",
    "Xn_tulio_embed = [tulio_embedder(document) for document in dataset[\"block_documents\"]]\n",
    "padded_tulio_documents = []\n",
    "for document in Xn_tulio_embed:\n",
    "    pad = np.concatenate(np.repeat([tulio_pad], PARAGRAPH_QTY-document.shape[0], axis=0), axis=0)\n",
    "    padded_tulio_documents.append(tf.concat([document, pad], 0))\n",
    "Xn_tulio_tensor = tf.convert_to_tensor(padded_tulio_documents)\n",
    "serialized_Xn_tulio = tf.io.serialize_tensor(Xn_tulio_tensor)\n",
    "with open(\"tulio_padded.tensor\", \"wb\") as file:\n",
    "    file.write(serialized_Xn_tulio.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"tulio_padded.tensor\", \"rb\") as file:\n",
    "    serialized_Xn_tulio_tensor = file.read()\n",
    "opened_Xn_tulio_tensor = tf.io.parse_tensor(serialized_Xn_tulio_tensor, out_type=float)    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_tulio = Sequential()\n",
    "model_tulio.add(Bidirectional(LSTM(512, return_sequences=True, input_shape=(PARAGRAPH_QTY, 768))))\n",
    "model_tulio.add(Bidirectional(LSTM(units=512, return_sequences=False)))\n",
    "model_tulio.add(Dense(256, activation=\"relu\"))\n",
    "model_tulio.add(Dense(4, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_total = clone_model(model_tulio)\n",
    "model_tulio_total.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_total.fit(opened_Xn_tulio_tensor, labels_total, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_total.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_contenido = clone_model(model_tulio)\n",
    "model_tulio_contenido.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_contenido.fit(opened_Xn_tulio_tensor, labels_contenido, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_contenido.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_conclusiones = clone_model(model_tulio)\n",
    "model_tulio_conclusiones.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_conclusiones.fit(opened_Xn_tulio_tensor, labels_conclusiones, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_conclusiones.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_conocimiento = clone_model(model_tulio)\n",
    "model_tulio_conocimiento.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_conocimiento.fit(opened_Xn_tulio_tensor, labels_conocimiento, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_conocimiento.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_relevancia = clone_model(model_tulio)\n",
    "model_tulio_relevancia.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_relevancia.fit(opened_Xn_tulio_tensor, labels_relevancia, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_relevancia.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_estructura = clone_model(model_tulio)\n",
    "model_tulio_estructura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_estructura.fit(opened_Xn_tulio_tensor, labels_estructura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_estructura.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model_tulio_escritura = clone_model(model_tulio)\n",
    "model_tulio_escritura.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\", \"AUC\"])\n",
    "model_tulio_escritura.fit(opened_Xn_tulio_tensor, labels_escritura, validation_split=0.3, epochs=3, batch_size=BATCH_SIZE)\n",
    "model_tulio_escritura.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T12:36:37.140539300Z",
     "start_time": "2023-11-26T12:36:37.072806300Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Conocimiento y Toma de decisiones\n",
    "\n",
    "En esta primera iteración del proyecto, se demuestra cierta superioridad de los modelos tradicionales respecto a aquellos que aplican técnicas más avanzadas.\n",
    "\n",
    "## Modelos tradicionales\n",
    "Analizando los modelos tradicionales, se destacan varios aspectos:\n",
    "- La búsqueda de hiperparámetros por grilla, en varias ocasiones, entregaba valores que empeoraban el rendimiento del modelo en cuestión. Esto se puede deber dado que se usó una validación cruzada de tres plieges; esto ya que la clase de menor frecuencia solo tenía tres muestras, motivo por el cual SciKit-Learn obligaba usar dicha cantidad de plieges.\n",
    "- La composisición de modelos para múltiples salidas entregaban resultados bastante deplorables. Considerando que dichos resultados corresponden a la exactitud media entre las distintas salidas, se presume que aquellos elementos que no pueden ser analizados mediante TF-IDF como estructura pueden tener un bajo rendimiento, que a su vez baje su rendimiendo. Queda pendiente una mejor evaluación del los modelos por separado.\n",
    "- Dado los resultados obtenidos con los modelos multi salida, no se utilizaron los estimadores de calificación final.\n",
    "\n",
    "## Modelos avanzados\n",
    "Respecto a los modelos basados en Deep Learning, se destaca que, la mayor dificultad en su diseño correspondió a la forma de manejar los documentos de gran tamaño; se indagaron distintos modelos de representación capaces de manejar la cantidad de texto de los informes. Dada la gran cantidad de modelos de procesamiento de texto existente y el plazo del proyecto, se acotó el análisis a los modeos utilizados en el presente documento. Considerando los resultados obtenidos, se concluye que:\n",
    "- En general, los modelos presentan un rendimiento subóbtimo en términos de exactitud. Esto puede deberse a la rudimentaria forma de procesar los textos, en la que se incluía mucha información inutil para conocimiento, así como tambien se rompía la linearidad de un bloque contiguio de texto (se consideraban líneas de texto en vez de oraciones o parrafos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
